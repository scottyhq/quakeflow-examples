{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad701445-f762-4274-9ffc-f441e7d6e45e",
   "metadata": {},
   "source": [
    "# Getting started with Quakeflow\n",
    "\n",
    "https://github.com/wayneweiqiang/QuakeFlow\n",
    "\n",
    "\n",
    "Extension of demo notebooks looking at Ridgecrest Earthquake\n",
    "\n",
    "https://github.com/wayneweiqiang/QuakeFlow#data-process \n",
    "https://wayneweiqiang.github.io/QuakeFlow/workflow/\n",
    "\n",
    "\n",
    "https://earthquake.usgs.gov/storymap/index-ridgecrest.html "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234636fd-4974-413b-bbee-d8c5634254ea",
   "metadata": {},
   "source": [
    "## Configure software environment\n",
    "\n",
    "We've created a lock file to ensure a reproducible environment is created with locked package versions.\n",
    "\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate quakeflow\n",
    "conda list --explicit > conda-linux-64.lock\n",
    "```\n",
    "\n",
    "**Uncomment and run the following cell, then Kernel --> Change Kernel --> quakeflow. NOTE: you may need log out and log back in for the new kernel to appear.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d832c71d-e6e0-4ab7-a5cd-fa6ddff04dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('/home/studio-lab-user/.conda/envs/quakeflow'):\n",
    "    %conda create -y -n quakeflow --file conda-linux-64.lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596f919f-c7d5-49e7-b551-6b521c453756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "import json\n",
    "import obspy\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "# from google.colab import data_table\n",
    "# data_table.enable_dataframe_formatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946dc12a-6dbb-46fc-b4c8-ecd727d95f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional useful libraries\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cdb29-fa97-4127-8453-298b10556b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bdfbd1-9d58-41ad-b0e5-212397698dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting configuration\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403c07fa-b838-40fb-b8fa-321f487e00ec",
   "metadata": {},
   "source": [
    "## Get Data from API\n",
    "\n",
    "client = \"SCEDC\" # http://service.scedc.caltech.edu \"Southern California Earthquake Data Center\n",
    "\n",
    "CI: Southern California Seismic Network https://www.fdsn.org/networks/detail/CI/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb55c1a8-5b5c-4330-8870-955e4800056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_name = \"Ridgecrest_demo\"\n",
    "center = (-117.504, 35.705)\n",
    "horizontal_degree = 1.0\n",
    "vertical_degree = 1.0\n",
    "starttime = obspy.UTCDateTime(\"2019-07-04T17\")\n",
    "endtime = obspy.UTCDateTime(\"2019-07-04T18\")\n",
    "client = \"SCEDC\" # http://service.scedc.caltech.edu \"Southern California Earthquake Data Center\n",
    "network_list = [\"CI\"]\n",
    "# channel_list = \"HH*,BH*,EH*,HN*\"\n",
    "channel_list = \"HH*,BH*,EH*\"\n",
    "\n",
    "config = {}\n",
    "config[\"region\"] = region_name\n",
    "config[\"center\"] = center\n",
    "config[\"xlim_degree\"] = [center[0] - horizontal_degree / 2, center[0] + horizontal_degree / 2]\n",
    "config[\"ylim_degree\"] = [center[1] - vertical_degree / 2, center[1] + vertical_degree / 2]\n",
    "config[\"starttime\"] = starttime.datetime.isoformat()\n",
    "config[\"endtime\"] = endtime.datetime.isoformat()\n",
    "config[\"networks\"] = network_list\n",
    "config[\"channels\"] = channel_list\n",
    "config[\"client\"] = client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389673b6-e3d0-4eff-ae3f-e457c2b24b4e",
   "metadata": {},
   "source": [
    "### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b720846-e10e-46c9-a753-fbb79b4cf628",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = Client(\"iris\").get_events(\n",
    "    starttime=config[\"starttime\"],\n",
    "    endtime=config[\"endtime\"],\n",
    "    minlongitude=config[\"xlim_degree\"][0],\n",
    "    maxlongitude=config[\"xlim_degree\"][1],\n",
    "    minlatitude=config[\"ylim_degree\"][0],\n",
    "    maxlatitude=config[\"ylim_degree\"][1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d93356-dd0f-4465-847f-46373795c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns copy of plot as variable\n",
    "p = events.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af9f61-1721-41f6-a01b-b381b92c83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of events: {len(events)}\")\n",
    "\n",
    "####### Save catalog ########\n",
    "catalog = defaultdict(list)\n",
    "for event in events:\n",
    "    if len(event.magnitudes) > 0:\n",
    "        catalog[\"time\"].append(event.origins[0].time.datetime)\n",
    "        catalog[\"magnitude\"].append(event.magnitudes[0].mag)\n",
    "        catalog[\"longitude\"].append(event.origins[0].longitude)\n",
    "        catalog[\"latitude\"].append(event.origins[0].latitude)\n",
    "        catalog[\"depth(m)\"].append(event.origins[0].depth)\n",
    "\n",
    "catalog = pd.DataFrame.from_dict(catalog)#.sort_values([\"time\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "catalog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d09ba0-8ab9-40b6-965e-5e3530d1e809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a CSV\n",
    "catalog.to_csv(\n",
    "    'events.csv',\n",
    "    sep=\"\\t\",\n",
    "    index=False,\n",
    "    float_format=\"%.3f\",\n",
    "    date_format='%Y-%m-%dT%H:%M:%S.%f',\n",
    "    columns=[\"time\", \"magnitude\", \"longitude\", \"latitude\", \"depth(m)\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001b5fc-ebc1-485f-86a8-f6a592fe1aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can also save as GeoJSON\n",
    "gf = gpd.GeoDataFrame(catalog, \n",
    "                      geometry=gpd.points_from_xy(catalog.longitude, catalog.latitude),\n",
    "                      crs=4326,\n",
    "                     )\n",
    "gf.to_file('events.json', driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff236a-0388-43f1-9029-fb88013e5861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue with pandas timestamps\n",
    "# gf.explore() https://github.com/geopandas/geopandas/issues/1906 \n",
    "gf['time'] = gf.time.astype('str')\n",
    "gf.explore(column='magnitude', cmap='viridis', tiles='Stamen Terrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63cbfc6b-ebbb-48ab-a7b7-3816e2fcbeb0",
   "metadata": {},
   "source": [
    "### Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e836c959-743b-4fc0-bc1a-8ef2273fc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = Client(config[\"client\"]).get_stations(\n",
    "    network=\",\".join(config[\"networks\"]),\n",
    "    station=\"*\",\n",
    "    starttime=config[\"starttime\"],\n",
    "    endtime=config[\"endtime\"],\n",
    "    minlongitude=config[\"xlim_degree\"][0],\n",
    "    maxlongitude=config[\"xlim_degree\"][1],\n",
    "    minlatitude=config[\"ylim_degree\"][0],\n",
    "    maxlatitude=config[\"ylim_degree\"][1],\n",
    "    channel=config[\"channels\"],\n",
    "    level=\"response\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c56317-2661-40d2-a049-cfb9e34eb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = stations.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d78b405-4335-4541-ad33-5aa1697cfe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locs = defaultdict(dict)\n",
    "for network in stations:\n",
    "    for station in network:\n",
    "        for chn in station:\n",
    "            sid = f\"{network.code}.{station.code}.{chn.location_code}.{chn.code[:-1]}\"\n",
    "            if sid in station_locs:\n",
    "                station_locs[sid][\"component\"] += f\",{chn.code[-1]}\"\n",
    "                station_locs[sid][\"response\"] += f\",{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "            else:\n",
    "                component = f\"{chn.code[-1]}\"\n",
    "                response = f\"{chn.response.instrument_sensitivity.value:.2f}\"\n",
    "                dtype = chn.response.instrument_sensitivity.input_units.lower()\n",
    "                tmp_dict = {}\n",
    "                tmp_dict[\"longitude\"], tmp_dict[\"latitude\"], tmp_dict[\"elevation(m)\"] = (\n",
    "                    chn.longitude,\n",
    "                    chn.latitude,\n",
    "                    chn.elevation,\n",
    "                )\n",
    "                tmp_dict[\"component\"], tmp_dict[\"response\"], tmp_dict[\"unit\"] = component, response, dtype\n",
    "                station_locs[sid] = tmp_dict\n",
    "\n",
    "station_locs = pd.DataFrame.from_dict(station_locs, orient='index')\n",
    "station_locs[\"id\"] = station_locs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105daa18-2d03-46f7-a542-fd1150e1ea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0a3f69-4d03-4bf0-b804-1b0a442a9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_locs.to_csv('stations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9673bacf-3696-41d4-8844-f68def12961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive visualization with geopandas geodataframe\n",
    "gf = gpd.GeoDataFrame(station_locs.copy(), \n",
    "                      geometry=gpd.points_from_xy(station_locs.longitude, station_locs.latitude),\n",
    "                      crs=4326,\n",
    "                     )\n",
    "\n",
    "gf.to_file('stations.json', driver='GeoJSON')\n",
    "\n",
    "gf.explore()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418d5fa7-ac00-467f-b617-a36e0162ea3d",
   "metadata": {},
   "source": [
    "### Waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016bb808-14f8-4243-837c-bbfac676f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(config[\"client\"])\n",
    "interval = 30 #s\n",
    "# interval = 3600 #s\n",
    "\n",
    "# for event in events:\n",
    "def download(event, stations):\n",
    "    '''\n",
    "    For a given 'event' and 'stations' list download 30 second waveforms w/ 100Hz samping rate\n",
    "    \n",
    "    Output: obspy miniseed stream\n",
    "    '''\n",
    "    starttime = event[\"origins\"][0].time\n",
    "    endtime = starttime + interval\n",
    "\n",
    "    max_retry = 10\n",
    "    stream = obspy.Stream()\n",
    "    num_sta = 0\n",
    "    for network in stations:\n",
    "        for station in network:\n",
    "            print(f\"********{network.code}.{station.code}********\")\n",
    "            retry = 0\n",
    "            while retry < max_retry:\n",
    "                try:\n",
    "                    tmp = client.get_waveforms(\n",
    "                        network.code, station.code, \"*\", config[\"channels\"], starttime, endtime\n",
    "                    )\n",
    "                    for trace in tmp:\n",
    "                        if trace.stats.sampling_rate != 100:\n",
    "                            # print(trace)\n",
    "                            trace = trace.interpolate(100, method=\"linear\")\n",
    "                    #      trace = trace.detrend(\"spline\", order=2, dspline=5*trace.stats.sampling_rate)\n",
    "                    #      stream.append(trace)\n",
    "                    stream += tmp\n",
    "                    num_sta += len(tmp)\n",
    "                    break\n",
    "                except Exception as err:\n",
    "                    print(\"Error {}.{}: {}\".format(network.code, station.code, err))\n",
    "                    message = \"No data available for request.\"\n",
    "                    if str(err)[: len(message)] == message:\n",
    "                        break\n",
    "                    retry += 1\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "            if retry == max_retry:\n",
    "                print(f\"{fname}: MAX {max_retry} retries reached : {network.code}.{station.code}\")\n",
    "            \n",
    "    # stream.attach_response(stations)\n",
    "    # stream = stream.remove_sensitivity()\n",
    "    return stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30f7e6d-bfcd-4295-8340-f3dc7fc1b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "mseed = download(events[0], stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76c9be-e8cf-4cbf-9832-159c0b96b574",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(mseed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f249cf-1593-42c7-a1b5-d3c916cd93af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(mseed.__str__(extended=True))\n",
    "mseed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add309f-6dfe-4b23-bb57-a227211f7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.obspy.org/tutorial/code_snippets/waveform_plotting_tutorial.html\n",
    "\n",
    "# mseed.plot() #all channels all stations!\n",
    "# mseed.plot(type='section')\n",
    "\n",
    "t = mseed[0:3].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500e893-788b-4f4e-8dc0-8ee66542a802",
   "metadata": {},
   "source": [
    "#### Convert to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0527fa2e-8f7a-4622-9d8e-b07414d0076f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 100\n",
    "n_channel = 3\n",
    "dtype = \"float32\"\n",
    "amplitude = True\n",
    "remove_resp = True\n",
    "\n",
    "def convert_mseed(mseed, station_locs):\n",
    "    try:\n",
    "        mseed = mseed.detrend(\"spline\", order=2, dspline=5 * mseed[0].stats.sampling_rate)\n",
    "    except:\n",
    "        logging.error(f\"Error: spline detrend failed at file {fname}\")\n",
    "        mseed = mseed.detrend(\"demean\")\n",
    "    mseed = mseed.merge(fill_value=0)\n",
    "    starttime = min([st.stats.starttime for st in mseed])\n",
    "    endtime = max([st.stats.endtime for st in mseed])\n",
    "    mseed = mseed.trim(starttime, endtime, pad=True, fill_value=0)\n",
    "\n",
    "    for i in range(len(mseed)):\n",
    "        if mseed[i].stats.sampling_rate != sampling_rate:\n",
    "            logging.warning(\n",
    "                f\"Resampling {mseed[i].id} from {mseed[i].stats.sampling_rate} to {sampling_rate} Hz\"\n",
    "            )\n",
    "            mseed[i] = mseed[i].interpolate(sampling_rate, method=\"linear\")\n",
    "\n",
    "    order = ['3', '2', '1', 'E', 'N', 'Z']\n",
    "    order = {key: i for i, key in enumerate(order)}\n",
    "    comp2idx = {\"3\": 0, \"2\": 1, \"1\": 2, \"E\": 0, \"N\": 1, \"Z\": 2}\n",
    "\n",
    "    nsta = len(station_locs)\n",
    "    nt = max(len(mseed[i].data) for i in range(len(mseed)))\n",
    "    data = []\n",
    "    station_id = []\n",
    "    t0 = []\n",
    "    for i in range(nsta):\n",
    "        trace_data = np.zeros([nt, n_channel], dtype=dtype)\n",
    "        empty_station = True\n",
    "        # sta = station_locs.iloc[i][\"station\"]\n",
    "        sta = station_locs.index[i]\n",
    "        comp = station_locs.iloc[i][\"component\"].split(\",\")\n",
    "        if remove_resp:\n",
    "            resp = station_locs.iloc[i][\"response\"].split(\",\")\n",
    "            # resp = station_locs.iloc[i][\"response\"]\n",
    "\n",
    "        for j, c in enumerate(sorted(comp, key=lambda x: order[x[-1]])):\n",
    "\n",
    "            resp_j = float(resp[j])\n",
    "            if len(comp) != 3:  ## less than 3 component\n",
    "                j = comp2idx[c]\n",
    "\n",
    "            if len(mseed.select(id=sta + c)) == 0:\n",
    "                print(f\"Empty trace: {sta+c} {starttime}\")\n",
    "                continue\n",
    "            else:\n",
    "                empty_station = False\n",
    "\n",
    "            tmp = mseed.select(id=sta + c)[0].data.astype(dtype)\n",
    "            trace_data[: len(tmp), j] = tmp[:nt]\n",
    "\n",
    "            if station_locs.iloc[i][\"unit\"] == \"m/s**2\":\n",
    "                tmp = mseed.select(id=sta + c)[0]\n",
    "                tmp = tmp.integrate()\n",
    "                tmp = tmp.filter(\"highpass\", freq=1.0)\n",
    "                tmp = tmp.data.astype(dtype)\n",
    "                trace_data[: len(tmp), j] = tmp[:nt]\n",
    "            elif station_locs.iloc[i][\"unit\"] == \"m/s\":\n",
    "                tmp = mseed.select(id=sta + c)[0].data.astype(dtype)\n",
    "                trace_data[: len(tmp), j] = tmp[:nt]\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Error in {station_locs.iloc[i]['station']}\\n{station_locs.iloc[i]['unit']} should be m/s**2 or m/s!\"\n",
    "                )\n",
    "            \n",
    "            if remove_resp:\n",
    "                trace_data[:, j] /= resp_j\n",
    "                \n",
    "        if not empty_station:\n",
    "            data.append(trace_data)\n",
    "            station_id.append(sta)\n",
    "            t0.append(starttime.strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3])\n",
    "\n",
    "    data = np.stack(data)\n",
    "\n",
    "    meta = {\"data\": data, \"t0\": t0, \"station_id\": station_id, \"fname\": station_id}\n",
    "    \n",
    "    \n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33414c6-6f59-4b84-a716-9502eb71e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = convert_mseed(mseed, station_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dca7ec-d8e0-480e-a6b1-c72e098ab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ea678-1dc5-4457-aaf8-b5d4ada11e8b",
   "metadata": {},
   "source": [
    "## P/S Picks Phasenet\n",
    "\n",
    "The code below calls an API, posting a dictionary containing 'id', 'timestamp', 'numpy array' passed as a python list, and returns JSON with model-generated P and S picks (time, probability, type)\n",
    "\n",
    "I think this operates per trace and does not consider the fact that channels are from the same station / traces are for the same event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d0660-c7d8-4184-972b-24ca55a46655",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "PHASENET_API_URL = \"http://phasenet.quakeflow.com\"\n",
    "\n",
    "# req = {\"id\": meta[\"station_id\"], \n",
    "#        \"timestamp\": meta[\"t0\"],\n",
    "#        \"vec\": meta[\"data\"].tolist()}\n",
    "# resp = requests.post(f'{PHASENET_API_URL}/predict', json=req)\n",
    "# phasenet_picks = resp.json()\n",
    "\n",
    "batch = 4\n",
    "phasenet_picks = []\n",
    "for j in range(0, len(meta[\"station_id\"]), batch):\n",
    "    req = {\"id\": meta['station_id'][j:j+batch],\n",
    "        \"timestamp\": meta[\"t0\"][j:j+batch],\n",
    "        \"vec\": meta[\"data\"][j:j+batch].tolist()}\n",
    "\n",
    "    resp = requests.post(f'{PHASENET_API_URL}/predict', json=req)\n",
    "    phasenet_picks.extend(resp.json())\n",
    "\n",
    "print('PhaseNet picks')\n",
    "df = pd.DataFrame(phasenet_picks)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0432320-977c-44d5-8727-0fd6678bac6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later so you don't have to call API again\n",
    "df.to_csv('phasenet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8619f-f96a-4e20-8932-49afec3563a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot pick timestamps with waveforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e23e341-e899-47b8-bc50-f410cc2de972",
   "metadata": {},
   "source": [
    "## GaMMA\n",
    "\n",
    "Takes a set of P- and S-wave arrival picks from a network of stations and associates them into individual earthquake events\n",
    "\n",
    "\n",
    "NOTE: x,y,z domain bounds are set as parameters. Again, data is passed in JSON format as lists of phasenet_picks and station locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7150120c-419d-423b-a218-10df7a95b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAMMA_API_URL = \"http://gamma.quakeflow.com\"\n",
    "\n",
    "# stations_json = json.loads(station_locs.to_json(orient=\"records\"))\n",
    "stations_json = station_locs.to_dict(orient=\"records\")\n",
    "config_gamma = {'xlim_degree': config[\"xlim_degree\"], \n",
    "                'ylim_degree': config[\"ylim_degree\"],\n",
    "                'z(km)': [0, 41]}\n",
    "\n",
    "result = requests.post(f'{GAMMA_API_URL}/predict', json= {\"picks\": phasenet_picks, \n",
    "                                                          \"stations\": stations_json,\n",
    "                                                           \"config\": config_gamma})\n",
    "\n",
    "result = result.json()\n",
    "catalog_gamma = result[\"catalog\"]\n",
    "picks_gamma = result[\"picks\"]\n",
    "print(\"GaMMA catalog:\")\n",
    "dfC = pd.DataFrame(catalog_gamma)[[\"time\", \"latitude\", \"longitude\", \"depth(m)\", \"magnitude\", \"covariance\"]]\n",
    "display(dfC)\n",
    "print(\"GaMMA association:\")\n",
    "dfA = pd.DataFrame(picks_gamma)\n",
    "display(dfA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f7697-6a14-41c8-a5ab-29c486e25bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: optional you can run both phasenet and gamma with a single API call\n",
    "\n",
    "# PHASENET_API_URL = \"http://phasenet.quakeflow.com\"\n",
    "\n",
    "# req = {\"id\": meta[\"station_id\"], \n",
    "#        \"timestamp\": meta[\"t0\"],\n",
    "#        \"vec\": meta[\"data\"].squeeze().tolist(),\n",
    "#        \"stations\": stations_json,\n",
    "#        \"config\": config_gamma}\n",
    "\n",
    "# resp = requests.post(f'{PHASENET_API_URL}/predict_phasenet2gamma2ui', json=req)\n",
    "# print(resp.json())\n",
    "# result = resp.json()\n",
    "# catalog_gamma = result[\"catalog\"]\n",
    "# picks_gamma = result[\"picks\"]\n",
    "# print(\"Catalog:\")\n",
    "# display(pd.DataFrame(catalog_gamma)[[\"time\", \"latitude\", \"longitude\", \"depth(m)\", \"magnitude\", \"covariance\"]])\n",
    "# print(\"Association:\")\n",
    "# display(pd.DataFrame(picks_gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdabbd5-76f8-4663-9870-fee8517672b8",
   "metadata": {},
   "source": [
    "# Compare! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d790f6-d753-4af2-a460-8dc5c3eaab93",
   "metadata": {},
   "outputs": [],
   "source": [
    "event = events[0]\n",
    "print(event.origins[0])\n",
    "print(event.magnitudes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2296be-10cf-4bdf-97c3-c1961ab5360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003b0cc-36f4-4409-821b-9069333cb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c5bbfe-a7aa-48ff-9eda-ddd8d1ebc514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: depth is very different! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76688573-5da5-48bb-8a19-8d304ad52f22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quakeflow:Python",
   "language": "python",
   "name": "conda-env-quakeflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
